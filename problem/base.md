# 进阶基础步骤

## 1.知道Web的发展史，了解为什么互联和开放是知识结构形成最关键的一件事。

## 2.知道RDF，OWL，SPARQL这些W3C技术堆栈，知道它们的长处和局限。会使用RDF数据库和推理机。

## 3.了解一点描述逻辑基础，知道描述逻辑和一阶逻辑的关系。知道模型论，不然完全没法理解RDF和OWL。

## 4.了解图灵机和基本的算法复杂性。知道什么是决策问题、可判定性、完备性和一致性、P、NP、NExpTime。

## 5.最好再知道一点逻辑程序（Logic Programming），涉猎一点答集程序（Answer Set Programming），
## 知道LP和ASP的一些小工具。这些东西是规则引擎的核心。如果不满足于正则表达式和if-then-else，最好学一点这些。

## 6.精通正则表达式。熟悉regex的各种工具。从正则文法到自动机。不理解自动机很多高效的模式提取算法都理解不了。

## 7.熟悉常见的知识库，不必事事重新造轮子，如Freebase, Wikidata, Yago, DBPedia

## 8.熟悉结构化数据建模的基本方法，如ER，面向对象，UML，脑图。

## 9.学会使用一些本体编辑器，如Protege。（Palantir就是个价值120亿美元的本体编辑器）

## 10.熟悉任何一种关系数据库。会使用存储过程写递归查询。明白什么叫物化视图、传递闭包、推理闭包。

## 11.熟悉任何一种图数据库。明白图的局部索引和关系的全局索引的理论和实践性能差异。

## 12.熟悉词法分析的基本工具，如分词、词性标注

## 13.熟悉句法分析的基本工具，如成分分析、依存文法分析、深层文法分析

## 14.熟悉TFIDF、主题模型和分布式表示的基本概念和工具。知道怎么计算两个词的相似度、词和句子的关联度。

## 15.知道怎么做命名实体识别。知道一些常用的词表。知道怎么用规则做关系提取。

## 16.为了上述的深化，要掌握一些机器学习的基本概念，识别、分类、聚类、预测、回归。掌握一些机器学习工具包的使用。

## 17.谨慎地使用一些深度学习方法，最好在是了解了神经网络的局限之后，先玩玩BP。主要是用用LSTM。

## 18.了解前人已经建好的各种Lexical数据库，如Wordnet, framenet, BabelNet, PropBank。熟悉一些常用的Corpus。


## 19.知道信息检索的基本原理。知道各种结构的索引的代价。

## 20.掌握Lucene或者Solr/Elasticsearch的使用。

## 21.学会混合使用多种数据库，把结构化数据和非结构化数据放在一起使用。体会数据建模和查询的成本。

## 22. 学会一些概念原型工具，如Axure和Semantic Mediawiki。快速做MVP。
